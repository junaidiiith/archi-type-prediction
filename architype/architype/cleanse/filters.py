"""
Graph cleansing utilities handling dummy detection and LLM vetting.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List, Optional, Sequence, Tuple

import networkx as nx
from pydantic import ValidationError
from tqdm.auto import tqdm

from ..langgraph.base import LangGraph

from ..llm.base import LLMService
from ..llm.prompts.cleansing import (
    ModelMeaningfulnessPrompt, 
    ModelMeaningfulnessVerdict
)


@dataclass(frozen=True)
class DummyPattern:
    """
    Simple regex wrapper documenting why a node/edge label is considered dummy.
    """

    name: str
    regex: str
    description: str


DEFAULT_DUMMY_PATTERNS: Tuple[DummyPattern, ...] = (
    DummyPattern(
        name="numeric_suffix",
        regex=r"^(class|node|element|entity)[ _-]*\d+$",
        description="Autogenerated references such as 'Class_1', 'Node 42'.",
    ),
    DummyPattern(
        name="lorem_placeholders",
        regex=r"^(foo|bar|foobar|baz|lorem|ipsum|dummy|sample|test|temp)$",
        description="Classical programming placeholders indicating non-semantic content.",
    ),
    DummyPattern(
        name="single_letter",
        regex=r"^[a-zA-Z]$",
        description="Single-letter identifiers rarely appear in curated enterprise models.",
    ),
    DummyPattern(
        name="repeated_letters",
        regex=r"^([a-zA-Z])\1{2,}$",
        description="Repeating the same letter ('xxx', 'aaa') suggests filler content.",
    ),
)


def is_small_graph(graph: nx.DiGraph, *, min_edges: int, min_enr: float) -> bool:
    """
    Return True if the graph is too small to be meaningful.
    """

    if graph.number_of_edges() < min_edges:
        return True
    if graph.number_of_nodes() == 0:
        return True
    enr = graph.number_of_edges() / graph.number_of_nodes()
    return enr < min_enr


def find_dummy_labels(
    graph: nx.DiGraph,
    patterns: Sequence[DummyPattern] = DEFAULT_DUMMY_PATTERNS,
) -> List[str]:
    """
    Return all node names matching the dummy patterns.
    """

    import re

    compiled = [(p, re.compile(p.regex, flags=re.IGNORECASE)) for p in patterns]
    dummy_nodes: List[str] = []
    for node, data in graph.nodes(data=True):
        label = (data.get("name") or str(node)).strip()
        if not label:
            dummy_nodes.append(label)
            continue
        if any(regex.match(label) for _, regex in compiled):
            dummy_nodes.append(label)
    return dummy_nodes


def filter_dummy_named_graphs(
    graphs: Sequence[nx.DiGraph],
    *,
    min_edges: int,
    min_enr: float,
    dummy_ratio_threshold: float = 0.5,
    patterns: Sequence[DummyPattern] = DEFAULT_DUMMY_PATTERNS,
) -> Tuple[List[nx.DiGraph], List[nx.DiGraph]]:
    """
    Split the graphs into meaningful vs dummy based on heuristics.
    """

    meaningful: List[nx.DiGraph] = []
    flagged: List[nx.DiGraph] = []

    for graph in graphs:
        if is_small_graph(graph, min_edges=min_edges, min_enr=min_enr):
            flagged.append(graph)
            continue

        dummy_nodes = find_dummy_labels(graph, patterns=patterns)
        ratio = (
            len(dummy_nodes) / graph.number_of_nodes()
            if graph.number_of_nodes()
            else 1.0
        )
        if dummy_nodes and ratio >= dummy_ratio_threshold:
            flagged.append(graph)
        else:
            meaningful.append(graph)

    return meaningful, flagged


# ---------------------------------------------------------------------------
# LLM-assisted cleansing
# ---------------------------------------------------------------------------


def serialize_edge_names_only(graph: nx.DiGraph, edge: Tuple[str, str]) -> str:
    src, tgt = edge
    src_name = (graph.nodes[src].get("name") or str(src)).strip()
    tgt_name = (graph.nodes[tgt].get("name") or str(tgt)).strip()
    return f"{src_name} -> {tgt_name}"


def chunked(iterable: Sequence[str], chunk_size: int) -> Iterable[List[str]]:
    for start in range(0, len(iterable), chunk_size):
        yield list(iterable[start : start + chunk_size])


def llm_score_graph(
    graph: nx.DiGraph,
    *,
    prompt: Optional[ModelMeaningfulnessPrompt] = None,
    batch_size: int = 100,
    threshold: float = 0.5,
) -> Tuple[bool, str]:
    """
    Query an LLM to assess whether the model is meaningful.
    """

    if prompt is None:
        prompt = ModelMeaningfulnessPrompt()

    edges = [serialize_edge_names_only(graph, edge) for edge in graph.edges]
    if not edges:
        return False, "Graph contains no edges."

    verdicts: List[ModelMeaningfulnessVerdict] = []
    for batch_idx, edge_batch in enumerate(chunked(edges, batch_size), start=1):
        messages = prompt.build_messages(
            edges="\n".join(f"- {edge}" for edge in edge_batch),
            edge_count=len(edges),
            batch=batch_idx,
            batch_size=len(edge_batch),
            batch_total=(len(edges) + batch_size - 1) // batch_size,
        )
        raw_response = LLMService.get_llm_response(
            messages,
            response_format=prompt.response_model,
            function_name=f"{prompt.name}_batch_{batch_idx}",
        )

        if isinstance(raw_response, prompt.response_model):
            verdict = raw_response
        elif isinstance(raw_response, dict):
            verdict = prompt.response_model(**raw_response)
        else:
            try:
                verdict = prompt.response_model.model_validate(raw_response)  # type: ignore[arg-type]
            except ValidationError as exc:
                raise ValueError(f"Unexpected LLM response: {raw_response}") from exc
        verdicts.append(verdict)

    is_meaningful = len([v for v in verdicts if v.is_meaningful]) / len(verdicts) >= threshold
    rationale = "\n".join(f"Meaningful: {v.is_meaningful}, Rationale: {v.rationale}" for v in verdicts)
    return is_meaningful, rationale


def llm_filter_graphs(
    graphs: Sequence[nx.DiGraph],
    *,
    prompt: ModelMeaningfulnessPrompt = ModelMeaningfulnessPrompt(),
    batch_size: int = 100,
    threshold: float = 0.5,
) -> Tuple[List[LangGraph], List[Tuple[LangGraph, str]]]:
    """
    Split graphs into meaningful vs flagged using the LLM prompt.
    """

    meaningful: List[nx.DiGraph] = []
    flagged: List[Tuple[nx.DiGraph, str]] = []

    for graph in tqdm(graphs, desc="Scoring graphs", total=len(graphs), unit="graph"):
        verdict, rationale = llm_score_graph(
            graph,
            prompt=prompt,
            batch_size=batch_size,
            threshold=threshold,
        )
        if verdict:
            meaningful.append(graph)
        else:
            flagged.append((graph, rationale))

    return meaningful, flagged


__all__ = [
    "DummyPattern",
    "DEFAULT_DUMMY_PATTERNS",
    "find_dummy_labels",
    "filter_dummy_named_graphs",
    "llm_score_graph",
    "llm_filter_graphs",
    "serialize_edge_names_only",
    "is_small_graph",
]
